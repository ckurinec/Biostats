[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Cheat Sheet Quarto2.html#preface",
    "href": "Cheat Sheet Quarto2.html#preface",
    "title": "Biostats Cheat Sheet",
    "section": "1 Preface",
    "text": "1 Preface\nHello! There are many different ways to do many different things. This cheat sheet is meant to help us get started with handling data. Some days it can be difficult to remember the expansive vocabulary that R uses, and some days we’re just tired and our brains don’t want to work. This guide is for those days, supplying a simple scaffolding to us to apply to our data so that we can actually use it. Again, there are many different ways to do many different things. Nothing in this document is right or wrong, but it is certainly something. Hopefully, that something is helpful.\n-Chris"
  },
  {
    "objectID": "Cheat Sheet Quarto2.html#how-to-use-this-guide",
    "href": "Cheat Sheet Quarto2.html#how-to-use-this-guide",
    "title": "Biostats Cheat Sheet",
    "section": "2 How to use this guide",
    "text": "2 How to use this guide\nThis guide is written in something called a “Quarto” document. Quarto is an extension of R Markdown, which is R’s way of combing a notepad which we can free type like this, with a runnable R script like this:\n\nprint(\"Hello!\")\n\n[1] \"Hello!\"\n\n\nThe vast majority of this guide with be examples of different R vocabularies and functions that are commonly used for each process. Each process is represented by its own section, such as “Exploring Data”. Many of these functions will repeat themselves in other sections, because there are no rules and I can do whatever I want.\nThis guide WILL be using the tidyverse package, since many of the functions we have learned about come from those packages.\n\nlibrary(tidyverse)\n\nThings that are NOT in this guide:\n\nStylistic choices\nHow to download R\nHow to find/ set a working directory\nPrecisely explaining what every function does\nHow to make your own Quarto document\nRecipes for any kind of baked good"
  },
  {
    "objectID": "Cheat Sheet Quarto2.html#functions-and-for-play",
    "href": "Cheat Sheet Quarto2.html#functions-and-for-play",
    "title": "Biostats Cheat Sheet",
    "section": "3 Functions and For-play",
    "text": "3 Functions and For-play\nMany of the codes within the guide are great on their own, but to save time and mental well-being we can combine many of these into our own functions and for loops that are specific to the problems we encounter within our specific datasets. In general, if you have to type a long sequence of code more than twice, just turn it into a function and call the function instead. These functions can also be used within loops and maps and you can generate some pretty creative solutions. Loops and maps are great for any monotonous task that nobody has time for, such as sampling 1000 times or running the same function over 150 different columns. These can get much more complicated and are worth playing around with.\n\n3.1 Functions\nFunctions help you do a lot of things in R. That’s a pretty generic description, but basically you give R an input (could be x, but could be many different things), and R will give you whatever you want back. Honestly functions are super cool because you can do a lot of things with them. I’m sure there are much more sophisticated explanations out there, but the general format of a function in R is this: \n\nfx &lt;- function(x){   \n  fluff &lt;- x^2 # can be whatever you want   \n  return(fluff) \n}\n\nfx(4) # should give us 16 \n\n[1] 16\n\n\n\n\n3.2 For Loops\nFor loops help you run a function or desired manipulation across multiple values. This could be across multiple columns in a data set, which will save you a lot of time and stress in the long run, so you don’t spend hours trying to do the same function over and over again.\nHere’s the basic format:\n\nn &lt;- 100 # n would be the number of times you want this loop to run.  \n\nfor(i in 1:n){\n  random_vector &lt;- c(3, 4, 5, 6, 7, 8, 9, 10)\n  new_thing &lt;- sample(random_vector, size = 2, replace = T)\n  do_something &lt;- sum(new_thing)^2\n  return(do_something)\n  }\n\nprint(do_something)\n\n[1] 100\n\n\nThis will run 100 samples from this vector and sum & square them. Not a very practical or useful example, but this just shows you what functions can do! You can put whatever your heart desires into those little brackets."
  },
  {
    "objectID": "Cheat Sheet Quarto2.html#finding-a-dataset",
    "href": "Cheat Sheet Quarto2.html#finding-a-dataset",
    "title": "Biostats Cheat Sheet",
    "section": "4 Finding a Dataset",
    "text": "4 Finding a Dataset\nYou don’t have to harass a bunch of physicians in order to find a data et. In face, you really can just google them. Here are some websites to find all the datasets you could ever want:\n\nKaggle\n\nhttps://www.kaggle.com/\n\nGoogle Datasets\n\nhttps://datasetsearch.research.google.com/\n\nGitHub\n\nhttps://github.com/\n\nGumnit Data\n\nhttps://data.gov/\n\nNASA data\n\nhttps://data.nasa.gov/browse?limitTo=datasets\n\n\nIf you have found a data set and don’t know where to start, just go through these sections in order. You likely won’t need every function for every data set and you may need more.\n\n4.1 Reading in your data\nOnce you have your data (usually an excel or csv file), there are a few ways you can read it into your R script. There are some data sets already pre-loaded into the R universe, such as the diamonds data set that we often use in Biostats. I think csv files are superior to excel files, but I can’t honestly explain why, you could probably look it up though. My favorite ways to load in data are these:\n\n# Read in as a tibble\ndiamond_tibble &lt;- read_csv(\"diamond.csv\")\n\nRows: 53940 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): cut, color, clarity\ndbl (7): carat, depth, table, price, x, y, z\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# when you use read_csv with an underscore, it's a tibble. WILD \n\n# Read in as a data frame\ndiamond_df &lt;- read.csv(\"diamond.csv\")\n# when you read in read.csv with a period, it's a DATAFRAME. WILD\n\nAlso, if you want to know the difference between tibbles and data frames, look it up in the textbook!\n\n\n4.2 Importing from Excel\nSometimes the dataset that you’re looking at is not readily available as a csv, but it is as an Excel file (xlsx). Sure, you could open it in excel, clean it up, and convert it to a csv, but that’s one too many steps for me. I would recommend cleaning up the rows and columns in excel first, however. Many excel files have the first several rows as different labels cover many different columns, and sometimes they don’t even start at the top right cell and the entire dataset is randomly in the center of the spreadsheet. You can fix this in R, but excel is much quicker if you can since you can just drag and select the data you want then save that data as another xlsx file. Then you can import into R!\nFirst, make sure you set your working directory where it needs to be. Then, click the “Files” tab (in the lower right quadrant of RStudio by default).\n\nHere, you’ll see all of the files within your current working directory. You can move in and out of this directory to find the data set you want if needed. Once you find your xlsx file, click it and select “Import Dataset”.\n\nThis will pull up a large pop-up menu. This menu will provide a preview of how R thinks the excel file should look in R. Pay attention to the rows and columns in the preview. If the excel file had many different section headers, this file may look wonky and you may need to rearrange it in excel first. Remember that R can also make the first column the row names, so if that column existed in excel you may end up with 2 columns of called No. containing 1, 2, 3, 4, and so on.\nIn the bottom right of this pop-up, you will find the R code to copy and paste into your R script in order to import the xlsx file. I prefer to copy the code, close out of the window, and paste directly into my script. You could also just click “Import” in the bottom right, but that will only load your data into your environment and you will not have any code written to reset it if needed.\n\nAnd that’s it! Now you can run the code provided to import your Excel file and have so much fun. All of your friends will be jealous, and you can sell them this information for money, thus solving any financial problems too. Its the gift that just keeps giving."
  },
  {
    "objectID": "Cheat Sheet Quarto2.html#exploring-data",
    "href": "Cheat Sheet Quarto2.html#exploring-data",
    "title": "Biostats Cheat Sheet",
    "section": "5 Exploring Data",
    "text": "5 Exploring Data\nExploring your data does not refer to anything complicated. This is the first step after downloading your data set. We need to look at it, and see what the heck is going on in there. Looking at our data, we want to understand how many rows and columns there are, what classes (numerical, categorical, factor, etc.) are our variables, how many unique observations are there, what different names are used throughout the data, and so on. If we do not know what our data looks like, it will be pretty difficult to know what to do next.\nSo here’s some common functions we can use for this:\n\n5.1 Looking at the data\n\n# View the entire dataset in another window\nView(diamonds)\n\n# View the first 6 rows of a dataset\nhead(diamonds)\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n# View the last 6 rows of a dataset\ntail(diamonds)\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.72 Premium   D     SI1      62.7    59  2757  5.69  5.73  3.58\n2  0.72 Ideal     D     SI1      60.8    57  2757  5.75  5.76  3.5 \n3  0.72 Good      D     SI1      63.1    55  2757  5.69  5.75  3.61\n4  0.7  Very Good D     SI1      62.8    60  2757  5.66  5.68  3.56\n5  0.86 Premium   H     SI2      61      58  2757  6.15  6.12  3.74\n6  0.75 Ideal     D     SI2      62.2    55  2757  5.83  5.87  3.64\n\n# List of variables with additional info by class\nsummary(diamonds)\n\n     carat               cut        color        clarity          depth      \n Min.   :0.2000   Fair     : 1610   D: 6775   SI1    :13065   Min.   :43.00  \n 1st Qu.:0.4000   Good     : 4906   E: 9797   VS2    :12258   1st Qu.:61.00  \n Median :0.7000   Very Good:12082   F: 9542   SI2    : 9194   Median :61.80  \n Mean   :0.7979   Premium  :13791   G:11292   VS1    : 8171   Mean   :61.75  \n 3rd Qu.:1.0400   Ideal    :21551   H: 8304   VVS2   : 5066   3rd Qu.:62.50  \n Max.   :5.0100                     I: 5422   VVS1   : 3655   Max.   :79.00  \n                                    J: 2808   (Other): 2531                  \n     table           price             x                y         \n Min.   :43.00   Min.   :  326   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:56.00   1st Qu.:  950   1st Qu.: 4.710   1st Qu.: 4.720  \n Median :57.00   Median : 2401   Median : 5.700   Median : 5.710  \n Mean   :57.46   Mean   : 3933   Mean   : 5.731   Mean   : 5.735  \n 3rd Qu.:59.00   3rd Qu.: 5324   3rd Qu.: 6.540   3rd Qu.: 6.540  \n Max.   :95.00   Max.   :18823   Max.   :10.740   Max.   :58.900  \n                                                                  \n       z         \n Min.   : 0.000  \n 1st Qu.: 2.910  \n Median : 3.530  \n Mean   : 3.539  \n 3rd Qu.: 4.040  \n Max.   :31.800  \n                 \n\n\n\n\n5.2 Structure of the data\n\n# View a list of all variables with variable type\nglimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n# View a list of all variables with variable class\nstr(diamonds)\n\ntibble [53,940 × 10] (S3: tbl_df/tbl/data.frame)\n $ carat  : num [1:53940] 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ...\n $ cut    : Ord.factor w/ 5 levels \"Fair\"&lt;\"Good\"&lt;..: 5 4 2 4 2 3 3 3 1 3 ...\n $ color  : Ord.factor w/ 7 levels \"D\"&lt;\"E\"&lt;\"F\"&lt;\"G\"&lt;..: 2 2 2 6 7 7 6 5 2 5 ...\n $ clarity: Ord.factor w/ 8 levels \"I1\"&lt;\"SI2\"&lt;\"SI1\"&lt;..: 2 3 5 4 2 6 7 3 4 5 ...\n $ depth  : num [1:53940] 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ...\n $ table  : num [1:53940] 55 61 65 58 58 57 57 55 61 61 ...\n $ price  : int [1:53940] 326 326 327 334 335 336 336 337 337 338 ...\n $ x      : num [1:53940] 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ...\n $ y      : num [1:53940] 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ...\n $ z      : num [1:53940] 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ...\n\n# View the total number of rows and columns\ndim(diamonds)\n\n[1] 53940    10\n\n# View the total number of columns\nlength(diamonds)\n\n[1] 10\n\n# View the total number of columns\nncol(diamonds)\n\n[1] 10\n\n# View the total number of rows\nnrow(diamonds)\n\n[1] 53940\n\n\n\n\n5.3 Class and names of variables\n\n# View the variable names of a dataset. Can be used on a vector\nnames(diamonds)\n\n [1] \"carat\"   \"cut\"     \"color\"   \"clarity\" \"depth\"   \"table\"   \"price\"  \n [8] \"x\"       \"y\"       \"z\"      \n\n# View the class of a variable, such as numerical or factor\nclass(diamonds$carat)\n\n[1] \"numeric\"\n\n# View all values without repeats\nunique(diamonds$cut)\n\n[1] Ideal     Premium   Good      Very Good Fair     \nLevels: Fair &lt; Good &lt; Very Good &lt; Premium &lt; Ideal\n\n\n\n\n5.4 Tables and plots of data\n\n# Plot a table of counts with totals added\ndiamonds |&gt; \n  select(cut, color) |&gt; \n  table() |&gt; \n  addmargins()\n\n           color\ncut             D     E     F     G     H     I     J   Sum\n  Fair        163   224   312   314   303   175   119  1610\n  Good        662   933   909   871   702   522   307  4906\n  Very Good  1513  2400  2164  2299  1824  1204   678 12082\n  Premium    1603  2337  2331  2924  2360  1428   808 13791\n  Ideal      2834  3903  3826  4884  3115  2093   896 21551\n  Sum        6775  9797  9542 11292  8304  5422  2808 53940\n\n# Plot a table of proportions \ndiamonds$cut |&gt; \n  table() |&gt; \n  prop.table()\n\n\n      Fair       Good  Very Good    Premium      Ideal \n0.02984798 0.09095291 0.22398962 0.25567297 0.39953652 \n\n# Plot a histogram of a continuous variable to check distribution\ndiamonds |&gt; \n  ggplot(aes(x = log(price))) +\n  geom_histogram(binwidth = 0.3, \n                        color = \"black\", \n                        fill = \"turquoise\") +\n  labs(title = \"On the 'Gram\", x = \"log(price)\", y = \"Count\") +\n  theme_bw()\n\n\n\n# Plot a bar plot of a categorical variable to check distribution\ndiamonds |&gt; \n  ggplot(aes(x = cut)) +\n  geom_bar(fill = \"lightblue\", color = \"black\") +\n  labs(title = \"At the Bar\", x = \"Cut\", y = \"Count\") +\n  theme_bw()"
  },
  {
    "objectID": "Cheat Sheet Quarto2.html#cleaning-data",
    "href": "Cheat Sheet Quarto2.html#cleaning-data",
    "title": "Biostats Cheat Sheet",
    "section": "6 Cleaning Data",
    "text": "6 Cleaning Data\nUnfortunately, this step does not include soap. But that shouldn’t stop you from using any. Clean data is the data that you want. All of the variables are the correct class, any missing or duplicate data is identified and addressed, any values that need to be re-coded are taken care of, and that we’re left with data that we actually care about. Well, as much as a person “could” care about data.\nAnyways, more functions:\n\n6.1 Identifying variable types and class\n\n# View a list of all variables with variable class\nglimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n# View the class of a variable or dataframe\nclass(diamonds$carat)\n\n[1] \"numeric\"\n\n# View the unique levels within an ordinal factor. \n# The order of these levels matter\nlevels(diamonds$cut)\n\n[1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"    \n\n# View the non-repeating unique values\nunique(diamonds$cut)\n\n[1] Ideal     Premium   Good      Very Good Fair     \nLevels: Fair &lt; Good &lt; Very Good &lt; Premium &lt; Ideal\n\n\n\n\n6.2 Choosing the data we want\n\n# Only selects the variables chosen\ndiamonds |&gt; \n  select(cut, color)\n\n# A tibble: 53,940 × 2\n   cut       color\n   &lt;ord&gt;     &lt;ord&gt;\n 1 Ideal     E    \n 2 Premium   E    \n 3 Good      E    \n 4 Premium   I    \n 5 Good      J    \n 6 Very Good J    \n 7 Very Good I    \n 8 Very Good H    \n 9 Fair      E    \n10 Very Good H    \n# ℹ 53,930 more rows\n\n# Only considers observations which meet the criteria specified\ndiamonds |&gt; \n  filter(color == \"D\", carat &gt;= mean(carat))\n\n# A tibble: 2,000 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.91 Ideal     D     SI2      62.2    57  2803  6.21  6.15  3.85\n 2  0.81 Premium   D     SI2      59.2    57  2809  6.15  6.05  3.61\n 3  0.83 Very Good D     SI1      63.5    54  2811  5.98  5.95  3.79\n 4  0.92 Ideal     D     SI2      61.9    56  2840  6.27  6.2   3.86\n 5  0.8  Very Good D     SI2      62.5    59  2862  5.88  5.92  3.69\n 6  1.08 Premium   D     I1       61.9    60  2869  6.55  6.48  4.03\n 7  0.9  Fair      D     SI2      66.9    57  2885  6.02  5.9   3.99\n 8  0.83 Very Good D     SI2      63.1    57  2918  5.95  5.9   3.74\n 9  0.8  Very Good D     SI1      58.2    63  2925  6.07  6.03  3.52\n10  0.81 Good      D     SI2      63.6    55  2926  5.91  5.86  3.74\n# ℹ 1,990 more rows\n\n# Shows the non-repeating values \nunique(diamonds$clarity)\n\n[1] SI2  SI1  VS1  VS2  VVS2 VVS1 I1   IF  \nLevels: I1 &lt; SI2 &lt; SI1 &lt; VS2 &lt; VS1 &lt; VVS2 &lt; VVS1 &lt; IF\n\n# Randomly selects values of the size and distribution specified. \n# \"replace\" determines whether a value can occur more than once. \ndiamonds$carat |&gt; \n  sample(size = 5, replace = TRUE)\n\n[1] 0.80 0.56 1.50 0.31 0.94\n\n\n\n\n6.3 Duplicated data\n\n# Creates a vector with a value occuring more than once\nexample.vector &lt;- c(1, 1, 2, 3, 4)\n\n# Gives a logical answer to whether a value has occured before\nduplicated(example.vector)\n\n[1] FALSE  TRUE FALSE FALSE FALSE\n\n# Gives all non-repeating values\nunique(example.vector)\n\n[1] 1 2 3 4\n\n\n\n\n6.4 Recoding data\n\n# Re-labels values from the old value, to the new\nrecode(example.vector, \"1\" = 7)\n\n[1] 7 7 2 3 4\n\n\n\n\n6.5 Addressing NAs:\nMissing values are about as complicated as you want them to be. For that reason, I will NOT be going over how to decide whether your data is missing completely at random (MCAR), missing at random (MAR), missing not at random (MNAR), or what the best practice for imputation will be for your specific data set. In general, NAs are either removed, imputed by the mean, replaced by the value before or after it, or predicted using the information around it (pmm, knn, rf, “mice” package, etc.). Look these strategies up at your own risk, it’ll take your entire weekend.\n\n\n6.6 Identifying NAs\n\n# Creates a vector with 3 NAs\nexample.vector &lt;- c(NA, 2, 3, NA, 4, 5, NA)\n\n# Counts the total number of NAs in the vector\nsum(is.na(example.vector))\n\n[1] 3\n\n# Shows which cell the NAs are located\nwhich(is.na(example.vector))\n\n[1] 1 4 7\n\n\n\n\n6.7 Removing NAs\n\n# Shows only the observations without NAs (specify [row, col] if using dataframe)\nexample.vector[complete.cases(example.vector)]\n\n[1] 2 3 4 5\n\n# Another way to show only the observations without NAs\nexample.vector[!is.na(example.vector)]\n\n[1] 2 3 4 5\n\n\n\n\n6.8 Simple mean imputation\n\n# Identifies the mean of our vector WITHOUT NAs\nmean(example.vector[!is.na(example.vector)])\n\n[1] 3.5\n\n# Overwrites the NAs in our vector with the value determined above\nexample.vector[is.na(example.vector)] &lt;- \n  mean(example.vector[!is.na(example.vector)])\n\nexample.vector\n\n[1] 3.5 2.0 3.0 3.5 4.0 5.0 3.5\n\n\n\n\n6.9 Replacing NAs with last/ next observation\n\n#The fill() function only works on a dataframe. So we create one\nexample.vector &lt;- as.data.frame(c(NA, 2, 3, NA, 4, 5, NA))\nexample.vector |&gt; \n    colnames() &lt;- \"example\"\n\nexample.vector\n\n  example\n1      NA\n2       2\n3       3\n4      NA\n5       4\n6       5\n7      NA\n\n\nIn the “fill” function, direction determines whether values are carried from above or below. In this case, The NAs are replaced with the value above it (down) first, leaving only the first NA. Then, the NAs are replaced with the value below it (up) in order to ensure no leading or trailing NAs. This also works on blank cells.\n\nexample.vector |&gt; \n  fill(everything(), .direction = \"downup\") \n\n  example\n1       2\n2       2\n3       3\n4       3\n5       4\n6       5\n7       5\n\n\nPrediction with KNN, RF, PMM, etc. is waaaay beyong this guide."
  },
  {
    "objectID": "Cheat Sheet Quarto2.html#manipulating-data",
    "href": "Cheat Sheet Quarto2.html#manipulating-data",
    "title": "Biostats Cheat Sheet",
    "section": "7 Manipulating Data",
    "text": "7 Manipulating Data\nWe shouldn’t judge a book by a cover. Unless its a data set, and we need the tools to set them straight. Manipulating data is self-explanatory. We take what data we have, and smack it around until it gives us the answers we need. This includes renaming, reordering, changing class, selecting, re-coding, changing, joining, and reshaping data.\nNo functions this time. You’ve had enough.\nJust kidding, they’re right here:\n\n7.1 Changing variable class\n\n# Create a new version any time you plan on making permanent changes\ndiamonds2 &lt;- diamonds\n\n# Changes cut from a categorical variable to a factor with ordinal levels\ndiamonds2$cut &lt;- as.factor(diamonds2$cut)\n\n# Shows the class of the cut variable\nclass(diamonds2$cut)\n\n[1] \"ordered\" \"factor\" \n\n# Shows the different levels of the cut variable. The order here matters. \nlevels(diamonds2$cut)\n\n[1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"    \n\n# Changing the levels and labels of the cut variable. The order here matters.\ndiamonds2 &lt;- diamonds2 |&gt; \n  mutate(cut = factor(cut,\n                      levels = c(\"Fair\", \"Good\", \"Very Good\", \"Ideal\", \"Premium\"),\n                      labels = c(\"Gross\", \"Icky\", \"Okay-ish\", \"Meh\", \"Sparkly\")))\n\ndiamonds2\n\n# A tibble: 53,940 × 10\n   carat cut      color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;    &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Meh      E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Sparkly  E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Icky     E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Sparkly  I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Icky     J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Okay-ish J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Okay-ish I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Okay-ish H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Gross    E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Okay-ish H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows\n\n\n\n\n7.2 Renaming columns\n\n# Rename variables by defining the new name first, then the old\ndiamonds2 |&gt; \n  rename(\"slice\" = \"cut\")\n\n# A tibble: 53,940 × 10\n   carat slice    color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;    &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Meh      E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Sparkly  E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Icky     E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Sparkly  I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Icky     J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Okay-ish J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Okay-ish I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Okay-ish H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Gross    E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Okay-ish H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows\n\n\n\n\n7.3 Reordering columns\n\n# The select function will always pull variables in the order you define\ndiamonds2 |&gt; \n  select(cut, clarity, everything())\n\n# A tibble: 53,940 × 10\n   cut      clarity carat color depth table price     x     y     z\n   &lt;ord&gt;    &lt;ord&gt;   &lt;dbl&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Meh      SI2      0.23 E      61.5    55   326  3.95  3.98  2.43\n 2 Sparkly  SI1      0.21 E      59.8    61   326  3.89  3.84  2.31\n 3 Icky     VS1      0.23 E      56.9    65   327  4.05  4.07  2.31\n 4 Sparkly  VS2      0.29 I      62.4    58   334  4.2   4.23  2.63\n 5 Icky     SI2      0.31 J      63.3    58   335  4.34  4.35  2.75\n 6 Okay-ish VVS2     0.24 J      62.8    57   336  3.94  3.96  2.48\n 7 Okay-ish VVS1     0.24 I      62.3    57   336  3.95  3.98  2.47\n 8 Okay-ish SI1      0.26 H      61.9    55   337  4.07  4.11  2.53\n 9 Gross    VS2      0.22 E      65.1    61   337  3.87  3.78  2.49\n10 Okay-ish VS1      0.23 H      59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows\n\n\n\n\n7.4 Selecting, Filtering, and Arranging\n\n# You can combine selecting, filtering, and arranging using pipes\ndiamonds2 |&gt; \n  select(cut, price) |&gt; \n  filter(cut == \"Okay-ish\") |&gt; \n  arrange(desc(price))\n\n# A tibble: 12,082 × 2\n   cut      price\n   &lt;ord&gt;    &lt;int&gt;\n 1 Okay-ish 18818\n 2 Okay-ish 18803\n 3 Okay-ish 18781\n 4 Okay-ish 18777\n 5 Okay-ish 18759\n 6 Okay-ish 18741\n 7 Okay-ish 18731\n 8 Okay-ish 18709\n 9 Okay-ish 18692\n10 Okay-ish 18691\n# ℹ 12,072 more rows\n\n\n\n\n7.5 Re-coding values\n\n# Recoding values can change the value to something more useful\ndiamonds2$color &lt;- diamonds2$color |&gt; \n  recode(\"E\" = \"blue\")\n\ndiamonds2\n\n# A tibble: 53,940 × 10\n   carat cut      color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;    &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Meh      blue  SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Sparkly  blue  SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Icky     blue  VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Sparkly  I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Icky     J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Okay-ish J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Okay-ish I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Okay-ish H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Gross    blue  VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Okay-ish H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows\n\n\n\n\n7.6 Changing data with mutate\n\n# Mutate can create a new variable, or change an existing one\ndiamonds2 |&gt; \n  mutate(carrot = carat) |&gt; \n  mutate(carat = mean(carat))\n\n# A tibble: 53,940 × 11\n   carat cut      color clarity depth table price     x     y     z carrot\n   &lt;dbl&gt; &lt;ord&gt;    &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 0.798 Meh      blue  SI2      61.5    55   326  3.95  3.98  2.43   0.23\n 2 0.798 Sparkly  blue  SI1      59.8    61   326  3.89  3.84  2.31   0.21\n 3 0.798 Icky     blue  VS1      56.9    65   327  4.05  4.07  2.31   0.23\n 4 0.798 Sparkly  I     VS2      62.4    58   334  4.2   4.23  2.63   0.29\n 5 0.798 Icky     J     SI2      63.3    58   335  4.34  4.35  2.75   0.31\n 6 0.798 Okay-ish J     VVS2     62.8    57   336  3.94  3.96  2.48   0.24\n 7 0.798 Okay-ish I     VVS1     62.3    57   336  3.95  3.98  2.47   0.24\n 8 0.798 Okay-ish H     SI1      61.9    55   337  4.07  4.11  2.53   0.26\n 9 0.798 Gross    blue  VS2      65.1    61   337  3.87  3.78  2.49   0.22\n10 0.798 Okay-ish H     VS1      59.4    61   338  4     4.05  2.39   0.23\n# ℹ 53,930 more rows\n\n# Mutate can be combined with other functions to make life easier\ndiamonds2 |&gt; \n  mutate(across(where(is.numeric), mean))\n\n# A tibble: 53,940 × 10\n   carat cut      color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;    &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 0.798 Meh      blue  SI2      61.7  57.5 3933.  5.73  5.73  3.54\n 2 0.798 Sparkly  blue  SI1      61.7  57.5 3933.  5.73  5.73  3.54\n 3 0.798 Icky     blue  VS1      61.7  57.5 3933.  5.73  5.73  3.54\n 4 0.798 Sparkly  I     VS2      61.7  57.5 3933.  5.73  5.73  3.54\n 5 0.798 Icky     J     SI2      61.7  57.5 3933.  5.73  5.73  3.54\n 6 0.798 Okay-ish J     VVS2     61.7  57.5 3933.  5.73  5.73  3.54\n 7 0.798 Okay-ish I     VVS1     61.7  57.5 3933.  5.73  5.73  3.54\n 8 0.798 Okay-ish H     SI1      61.7  57.5 3933.  5.73  5.73  3.54\n 9 0.798 Gross    blue  VS2      61.7  57.5 3933.  5.73  5.73  3.54\n10 0.798 Okay-ish H     VS1      61.7  57.5 3933.  5.73  5.73  3.54\n# ℹ 53,930 more rows\n\n\n\n\n7.7 Conditional changes with ifelse\n“ifelse” takes a condition you define as the “test” argument, and if the value meets those conditions it alters the value as you define it with the “yes” argument. If the value does not meet those conditions, it alters the value based upon how you defined the “no” argument.\n\ndiamonds2 |&gt; \n   mutate(price = (ifelse(\n     test = price &gt;= median(price), \n     yes = \"Can't Afford\", \n     no = \"Still Can't Afford\")))\n\n# A tibble: 53,940 × 10\n   carat cut      color clarity depth table price                  x     y     z\n   &lt;dbl&gt; &lt;ord&gt;    &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Meh      blue  SI2      61.5    55 Still Can't Afford  3.95  3.98  2.43\n 2  0.21 Sparkly  blue  SI1      59.8    61 Still Can't Afford  3.89  3.84  2.31\n 3  0.23 Icky     blue  VS1      56.9    65 Still Can't Afford  4.05  4.07  2.31\n 4  0.29 Sparkly  I     VS2      62.4    58 Still Can't Afford  4.2   4.23  2.63\n 5  0.31 Icky     J     SI2      63.3    58 Still Can't Afford  4.34  4.35  2.75\n 6  0.24 Okay-ish J     VVS2     62.8    57 Still Can't Afford  3.94  3.96  2.48\n 7  0.24 Okay-ish I     VVS1     62.3    57 Still Can't Afford  3.95  3.98  2.47\n 8  0.26 Okay-ish H     SI1      61.9    55 Still Can't Afford  4.07  4.11  2.53\n 9  0.22 Gross    blue  VS2      65.1    61 Still Can't Afford  3.87  3.78  2.49\n10  0.23 Okay-ish H     VS1      59.4    61 Still Can't Afford  4     4.05  2.39\n# ℹ 53,930 more rows\n\n\nUse “case_when” for multiple conditions at once. Note the syntax is different. The condition is on the left side of the ~ and if TRUE the values will be replaced by the right side of the ~. The final arugment “TRUE” specifies that if a value did not meet any of the conditions above, then replace it with whatever is right of the final ~.\n\ndiamonds2 |&gt; \n  mutate(price = case_when(\n  price &lt; quantile(price, probs = 0.33) ~ \"FREE\",\n  price &lt; quantile(price, probs = 0.66) ~ \"BUY NOW\",\n  price &lt; quantile(price, probs = 1) ~ \"SELL NOW\",\n  TRUE ~ \"NA\"))\n\n# A tibble: 53,940 × 10\n   carat cut      color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;    &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Meh      blue  SI2      61.5    55 FREE   3.95  3.98  2.43\n 2  0.21 Sparkly  blue  SI1      59.8    61 FREE   3.89  3.84  2.31\n 3  0.23 Icky     blue  VS1      56.9    65 FREE   4.05  4.07  2.31\n 4  0.29 Sparkly  I     VS2      62.4    58 FREE   4.2   4.23  2.63\n 5  0.31 Icky     J     SI2      63.3    58 FREE   4.34  4.35  2.75\n 6  0.24 Okay-ish J     VVS2     62.8    57 FREE   3.94  3.96  2.48\n 7  0.24 Okay-ish I     VVS1     62.3    57 FREE   3.95  3.98  2.47\n 8  0.26 Okay-ish H     SI1      61.9    55 FREE   4.07  4.11  2.53\n 9  0.22 Gross    blue  VS2      65.1    61 FREE   3.87  3.78  2.49\n10  0.23 Okay-ish H     VS1      59.4    61 FREE   4     4.05  2.39\n# ℹ 53,930 more rows\n\n\n\n\n7.8 Applying changes across a dataset\n\n# You can use a for loop for monotonous tasks like replacing every value with SPAM\nfor (i in seq_along(diamonds2)) {\n  diamonds2[[i]] &lt;- paste(\"SPAM\")\n}\n\ndiamonds2\n\n# A tibble: 53,940 × 10\n   carat cut   color clarity depth table price x     y     z    \n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 SPAM  SPAM  SPAM  SPAM    SPAM  SPAM  SPAM  SPAM  SPAM  SPAM \n 2 SPAM  SPAM  SPAM  SPAM    SPAM  SPAM  SPAM  SPAM  SPAM  SPAM \n 3 SPAM  SPAM  SPAM  SPAM    SPAM  SPAM  SPAM  SPAM  SPAM  SPAM \n 4 SPAM  SPAM  SPAM  SPAM    SPAM  SPAM  SPAM  SPAM  SPAM  SPAM \n 5 SPAM  SPAM  SPAM  SPAM    SPAM  SPAM  SPAM  SPAM  SPAM  SPAM \n 6 SPAM  SPAM  SPAM  SPAM    SPAM  SPAM  SPAM  SPAM  SPAM  SPAM \n 7 SPAM  SPAM  SPAM  SPAM    SPAM  SPAM  SPAM  SPAM  SPAM  SPAM \n 8 SPAM  SPAM  SPAM  SPAM    SPAM  SPAM  SPAM  SPAM  SPAM  SPAM \n 9 SPAM  SPAM  SPAM  SPAM    SPAM  SPAM  SPAM  SPAM  SPAM  SPAM \n10 SPAM  SPAM  SPAM  SPAM    SPAM  SPAM  SPAM  SPAM  SPAM  SPAM \n# ℹ 53,930 more rows\n\n# You can also use maps in a similar way, turning every value lower case\nmap_df(diamonds2, tolower)\n\n# A tibble: 53,940 × 10\n   carat cut   color clarity depth table price x     y     z    \n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 spam  spam  spam  spam    spam  spam  spam  spam  spam  spam \n 2 spam  spam  spam  spam    spam  spam  spam  spam  spam  spam \n 3 spam  spam  spam  spam    spam  spam  spam  spam  spam  spam \n 4 spam  spam  spam  spam    spam  spam  spam  spam  spam  spam \n 5 spam  spam  spam  spam    spam  spam  spam  spam  spam  spam \n 6 spam  spam  spam  spam    spam  spam  spam  spam  spam  spam \n 7 spam  spam  spam  spam    spam  spam  spam  spam  spam  spam \n 8 spam  spam  spam  spam    spam  spam  spam  spam  spam  spam \n 9 spam  spam  spam  spam    spam  spam  spam  spam  spam  spam \n10 spam  spam  spam  spam    spam  spam  spam  spam  spam  spam \n# ℹ 53,930 more rows\n\n\n\n\n7.9 Reshaping using pivots\n\n# Creates a data frame from class\nstocks &lt;- data.frame(\n     time = as.Date('2009-01-01') + 0:9,\n     X = rnorm(10, 0, 1),\n     Y = rnorm(10, 0, 2),\n     Z = rnorm(10, 0, 4)\n)\n\nSelect which columns to pivot longer with “cols”. The names of those columns will then go into a new column specified under “names_to”. The values within the old columns will go into their own new column specified with “values_to”.\n\nstocks &lt;- stocks |&gt; \n  pivot_longer(cols = c(X, Y, Z),\n               names_to = \"stonks\",\n               values_to = \"price\")\n\nstocks\n\n# A tibble: 30 × 3\n   time       stonks   price\n   &lt;date&gt;     &lt;chr&gt;    &lt;dbl&gt;\n 1 2009-01-01 X       0.833 \n 2 2009-01-01 Y       0.675 \n 3 2009-01-01 Z      -3.33  \n 4 2009-01-02 X       0.437 \n 5 2009-01-02 Y       3.25  \n 6 2009-01-02 Z       1.49  \n 7 2009-01-03 X       0.0695\n 8 2009-01-03 Y      -1.35  \n 9 2009-01-03 Z      -5.07  \n10 2009-01-04 X       1.23  \n# ℹ 20 more rows\n\n\nSimilarly in pivot_wider, the “names_from” will take the values of whatever column you choose and create new columns for every value within. In this case, the new columns will be called X, Y, and Z. The “values_from” argument will take every value from the column you choose and fill the new columns created by “names_from” with those values. In this case, the associated price will be listed under each of X, Y, and Z.\n\nstocks &lt;- stocks |&gt; \n  pivot_wider(names_from = stonks,\n              values_from = price)\n\nstocks\n\n# A tibble: 10 × 4\n   time             X      Y      Z\n   &lt;date&gt;       &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 2009-01-01  0.833   0.675 -3.33 \n 2 2009-01-02  0.437   3.25   1.49 \n 3 2009-01-03  0.0695 -1.35  -5.07 \n 4 2009-01-04  1.23    1.20   3.52 \n 5 2009-01-05  0.295  -0.762 -5.22 \n 6 2009-01-06 -0.421   2.22   5.20 \n 7 2009-01-07  0.999  -3.68  -1.26 \n 8 2009-01-08 -2.07    2.97   4.94 \n 9 2009-01-09  0.330   0.631 -3.71 \n10 2009-01-10 -1.36   -3.45  -0.408"
  },
  {
    "objectID": "Cheat Sheet Quarto2.html#describing-and-summarizing-data",
    "href": "Cheat Sheet Quarto2.html#describing-and-summarizing-data",
    "title": "Biostats Cheat Sheet",
    "section": "8 Describing and Summarizing Data",
    "text": "8 Describing and Summarizing Data\nThese steps are beginning to get more and more self-explanatory. The goal here is to use descriptive statistics to “describe” the data that we want to analyze. Shocking, I know. The statistics we’re looking for describe the range/spread, centrality, and variance of the data. These statistics can be summarized using the usual summary function, but also by using tables.\nAnd now functions:\n\n8.1 Range and spread\n\n# View the lowest and highest value \nrange(diamonds$carat)\n\n[1] 0.20 5.01\n\n# View the lowest value\nmin(diamonds$carat)\n\n[1] 0.2\n\n# View the highest value\nmax(diamonds$carat)\n\n[1] 5.01\n\n# Create a summary of your choosing \ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize(meanPrice = mean(price)) |&gt; \n  arrange(-desc(meanPrice))\n\n# A tibble: 5 × 2\n  cut       meanPrice\n  &lt;ord&gt;         &lt;dbl&gt;\n1 Ideal         3458.\n2 Good          3929.\n3 Very Good     3982.\n4 Fair          4359.\n5 Premium       4584.\n\n\n\n\n8.2 Centrality\n\n# View the average \nmean(diamonds$carat)\n\n[1] 0.7979397\n\n# View the median \nmedian(diamonds$carat)\n\n[1] 0.7\n\n# View a large summary with quantiles and medians for continuous data\nsummary(diamonds$carat)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2000  0.4000  0.7000  0.7979  1.0400  5.0100 \n\n\n\n\n8.3 Variance and standard deviation\n\n# View the variance \nvar(diamonds$carat)\n\n[1] 0.2246867\n\n# View the standard deviation\nsd(diamonds$carat)\n\n[1] 0.4740112"
  },
  {
    "objectID": "Cheat Sheet Quarto2.html#visualizing-data",
    "href": "Cheat Sheet Quarto2.html#visualizing-data",
    "title": "Biostats Cheat Sheet",
    "section": "9 Visualizing Data",
    "text": "9 Visualizing Data\nObviously this refers to plots, which means ggplot2 is coming. We want to tell a story with our data, and that comes from visualization. It becomes more and more difficult as you progress through these sections to be able to explain exactly what to do, as by this point your data is already unique to you. What I can do, is to help decide which plot to use depending on the types of variables that you’re left with at this point.\nBelow is a list of scenarios and some options for which plots to use:\n\n9.1 Single numerical variable only\n\n# Creates a histogram\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(fill = \"orange\", color = \"black\") +\n  labs(title =\"Histogram\", x = \"Carrot\", y = \"Count\") +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n# Creates a density plot\ndiamonds |&gt; \n  ggplot(aes(x = log(price))) +\n  geom_density(fill = \"pink\") +\n  labs(title = \"Dense\", x = \"Cost\", y = \"Frequency\") +\n  theme_bw()\n\n\n\n\n\n\n9.2 Single categorical only\n\n# Creates a bar plot\ndiamonds |&gt; \n  ggplot(aes(x = cut)) +\n  geom_bar(fill = \"green\", color = \"black\") +\n  labs(title = \"Bars\", x = \"Cuts\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n9.3 Multiple categorical only\n\n# Creates a stacked bar plot\ndiamonds |&gt; \n  ggplot(aes(x = cut, fill = color)) +\n  geom_bar(position = \"stack\") +\n  labs(title = \"Bars\", x = \"Cuts\", y = \"Count\") +\n  theme_bw() + \n  scale_fill_discrete()\n\n\n\n\n\n\n9.4 One numerical and one or more categorical\n\n# Creates a box plot\ndiamonds |&gt; \n  ggplot(aes(x = cut, y = log(price), fill = cut)) +\n  geom_boxplot() +\n  labs(title = \"Boxes\", x = \"Cut\", y = \"log(price)\") +\n  facet_wrap(~ clarity) +\n  theme_bw() + \n  scale_fill_discrete()\n\n\n\n\n\n\n9.5 One or more numerical and one or more categorical\n\n# Creates a scatterplot\ndiamonds |&gt; \n  ggplot(aes(x = log(carat), y = price, color = cut)) +\n  geom_point() +\n  labs(title = \"Points\", x = \"log(carat)\", y = \"Price\") +\n  theme_bw() + \n  scale_fill_continuous()"
  },
  {
    "objectID": "Cheat Sheet Quarto2.html#analyzing-data",
    "href": "Cheat Sheet Quarto2.html#analyzing-data",
    "title": "Biostats Cheat Sheet",
    "section": "10 Analyzing Data",
    "text": "10 Analyzing Data\nFinally. The end. Both of writing this guide, but also of your quest for usable data. Analyzing data is the generally the end goal of everything. We form a research question, and use analysis to get some insight on the question. There are as many different analyses as you can think of, then there will be even more because someone probably invented one while you were counting. I’ll only list the few we’ve gone over in class. What’s important when deciding which analysis to use is to make sure you understand the assumptions behind every test, and which test applies to which combinations of variables.\nWe’ll start with the T-Test:\n\n10.1 T-Test\n\nt.test(diamonds$carat)\n\n\n    One Sample t-test\n\ndata:  diamonds$carat\nt = 390.96, df = 53939, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.7939395 0.8019400\nsample estimates:\nmean of x \n0.7979397 \n\nwith(diamonds, t.test(carat, price, alternative = \"two.sided\"))\n\n\n    Welch Two Sample t-test\n\ndata:  carat and price\nt = -228.91, df = 53939, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3965.670 -3898.334\nsample estimates:\n   mean of x    mean of y \n   0.7979397 3932.7997219 \n\n\nAssumptions:\n\nData is randomly distributed\nData is continuous or 2 level categorical\nHomogeneity of variance\nDistribution is approximately normal/ t-distribution\n\n\n\n10.2 ANOVA\n\nwith(diamonds, lm(price ~ cut)) |&gt; \n  summary()\n\n\nCall:\nlm(formula = price ~ cut)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -4258  -2741  -1494   1360  15348 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4062.24      25.40 159.923  &lt; 2e-16 ***\ncut.L        -362.73      68.04  -5.331  9.8e-08 ***\ncut.Q        -225.58      60.65  -3.719    2e-04 ***\ncut.C        -699.50      52.78 -13.253  &lt; 2e-16 ***\ncut^4        -280.36      42.56  -6.588  4.5e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3964 on 53935 degrees of freedom\nMultiple R-squared:  0.01286,   Adjusted R-squared:  0.01279 \nF-statistic: 175.7 on 4 and 53935 DF,  p-value: &lt; 2.2e-16\n\nwith(diamonds, aov(price ~ clarity)) |&gt; \n  summary()\n\n               Df    Sum Sq   Mean Sq F value Pr(&gt;F)    \nclarity         7 2.331e+10 3.330e+09     215 &lt;2e-16 ***\nResiduals   53932 8.352e+11 1.549e+07                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAssumptions:\n\nNormal distribution\nHomogeneity of variance\nIndependent observations\n\n\n\n10.3 Linear Regressions\n\nwith(diamonds, lm(price ~ carat + cut + color)) |&gt; \n  summary()\n\n\nCall:\nlm(formula = price ~ carat + cut + color)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17313.9   -751.2    -83.9    543.6  12273.0 \n\nCoefficients:\n            Estimate Std. Error  t value Pr(&gt;|t|)    \n(Intercept) -3149.82      15.76 -199.905  &lt; 2e-16 ***\ncarat        8183.74      13.90  588.885  &lt; 2e-16 ***\ncut.L        1243.35      24.74   50.260  &lt; 2e-16 ***\ncut.Q        -531.75      21.93  -24.252  &lt; 2e-16 ***\ncut.C         372.06      19.16   19.417  &lt; 2e-16 ***\ncut^4          76.15      15.39    4.949 7.49e-07 ***\ncolor.L     -1579.17      21.72  -72.699  &lt; 2e-16 ***\ncolor.Q      -732.85      19.86  -36.902  &lt; 2e-16 ***\ncolor.C      -107.41      18.64   -5.763 8.32e-09 ***\ncolor^4        81.63      17.12    4.769 1.85e-06 ***\ncolor^5      -138.64      16.18   -8.568  &lt; 2e-16 ***\ncolor^6      -161.09      14.68  -10.973  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1432 on 53928 degrees of freedom\nMultiple R-squared:  0.8711,    Adjusted R-squared:  0.8711 \nF-statistic: 3.315e+04 on 11 and 53928 DF,  p-value: &lt; 2.2e-16\n\n\nAssumptions:\n\nThere should be a linear relationship between variables\nIndependent variables should not be correlated\nMultivariate normality\nHomogeneity of variance\nNo multicollinearity of variables\n\n\n\n10.4 Chi-Square test\n\nwith(diamonds, chisq.test(table(cut)))\n\n\n    Chi-squared test for given probabilities\n\ndata:  table(cut)\nX-squared = 22745, df = 4, p-value &lt; 2.2e-16\n\ndiamonds |&gt; \n  select(cut, clarity) |&gt; \n  table() |&gt; \n  chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  table(select(diamonds, cut, clarity))\nX-squared = 4391.4, df = 28, p-value &lt; 2.2e-16\n\n\nAssumptions:\n\nData in cells should be frequencies\nExpected frequencies must be greater than 5 per cell in 80% of cells\nLevels within variables must be mutually exclusive\nEach observation can only contribute to a single cell\nGroups must be independent\nData must be categorical or ordinal\n\n\n\n10.5 Logistic Regression\n\nnew.diamonds &lt;- diamonds |&gt; \n  mutate(binary = sample(rep(c(F, T)), \n                         size = nrow(diamonds), \n                         replace = T))\n\nwith(new.diamonds, glm(binary ~ cut + price, family = binomial)) |&gt; \n  summary()\n\n\nCall:\nglm(formula = binary ~ cut + price, family = binomial)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  3.160e-03  1.556e-02   0.203   0.8391  \ncut.L       -2.353e-02  3.435e-02  -0.685   0.4934  \ncut.Q        3.623e-02  3.061e-02   1.183   0.2366  \ncut.C       -6.185e-02  2.668e-02  -2.318   0.0204 *\ncut^4        2.349e-02  2.149e-02   1.093   0.2742  \nprice       -1.741e-06  2.173e-06  -0.801   0.4230  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 74776  on 53939  degrees of freedom\nResidual deviance: 74770  on 53934  degrees of freedom\nAIC: 74782\n\nNumber of Fisher Scoring iterations: 3\n\n\nAssumptions:\n\nBinary logistic regression requires a binary dependent variable\nOrdinal logistic regression requires (gasp) an ordinal dependent variable\nObservations must be disjoint\nLittle to no multicollinearity among independent variables\nAssumes linearity of independent variables and log odds, but not linearity of independent variables with dependent variable\nExpected probability of all independent variables must be at least 10%"
  },
  {
    "objectID": "Cheat Sheet Quarto2.html#conclusion",
    "href": "Cheat Sheet Quarto2.html#conclusion",
    "title": "Biostats Cheat Sheet",
    "section": "11 Conclusion",
    "text": "11 Conclusion\nThere is no conclusion. This is not a complete collection nor a guarantee of success with anything you might be doing. This is a random assortment of R-related functions to hopefully get us started. You may use everything in this guide, you may use nothing. Either way, this document should provide a framework to build upon throughout your struggles with data. So in conclusion, that is all."
  }
]